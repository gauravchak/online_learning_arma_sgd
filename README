Description of the model:

Step 1: Predicting the log return of each signal at all dates using the information till previous days.

x[t] = a_1 * x[t-1] + a_2 * x[t-2] + ....... + a_p * x[t-p] + c + b_1 * e[t-1] + b_2 * e[t-2] + ....... + b_q * e[t-q] 

where,
x[t] = log return of the signal at time t.
e[t] = actual_x[t] - predicted_x[t], denotes the prediction error at time instant t
c    = intercept
This is a ARMA(p,q) (Auto-regressive Moving Average Model). The parameters are estimated using Stochastic Gradient Descent assuming L2-norm as the loss function. 
Please Note: Either of p or q can be set to zero but they cannot be set to zero together simultaneously

In each iteration the update step is:
a_i = a_i - learning_rate * (x_predicted[t] - x_actual[t]) * x[t-i]
b_j = b_j - learning_rate * (x_predicted[t] - x_actual[t]) * e[t-j]

After making the predictions a log bias correction term to added to remove the bias which results when predictions are made in log domain. For more details refer: 
http://www.vims.edu/people/newman_mc/pubs/Newman1993.pdf

logBiasCorrection = (Mean Squared Error in the log domain)/2
therefore,
x[t] = x[t] + logBiasCorrection

Step 2: Assigning the weights.
To account for the risk we consider balancing_factor. 

The signals with positive returns are assigned weights in proportion of their predictions, which sum up to balancing_factor.
The signals with negative predictions are assigned weights in inverse ratio of their predicted magnitude and these weights sum up to ( 1 - balancing factor ).

julia eval.jl "path_of_the_file"